"""Data validation utilities for ML pipeline."""
def validate_dataset(df):
"""Validate dataset before processing."""
issues = []
# Check for null values
null_counts = df.isnull().sum()
if null_counts.any():
issues.append(f"Null values found: {null_counts[null_counts >
0].to_dict()}")
# Check for duplicate rows
duplicates = df.duplicated().sum()
if duplicates > 0:
issues.append(f"Duplicate rows found: {duplicates}")
return issues
def clean_dataset(df):
"""Basic dataset cleaning operations."""
# Remove duplicates
df_clean = df.drop_duplicates()
# Fill numeric nulls with median
numeric_columns = df_clean.select_dtypes(include=['number']).columns
df_clean[numeric_columns] = df_clean[numeric_columns].fillna(
df_clean[numeric_columns].median()
)
return df_clean